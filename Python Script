# import the necessary packages #
from __future__ import print_function 
from imutils.object_detection import non_max_suppression 
from imutils import paths 
import numpy as np 
import imutils 
import cv2 
# initialize the HOG descriptor/person detector #
hog = cv2.HOGDescriptor() 
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector()) 
video_capture = cv2.VideoCapture(0) 
while True:
ret, frame = video_capture.read() 
#loop over the image paths# 
for imagePath in paths.list_images(args["images"]): 
# load the image and resize it to (1) reduce detection time
# and (2) improve detection accuracy  
image = cv2.imread(imagePath)  
image = imutils.resize(image, width=min(400, image.shape[1]))
orig = image.copy()  
# detect people in the image #
(rects, weights) = hog.detectMultiScale(image, winStride=(4, 4),   
padding=(8, 8), scale=1.05)
# draw the original bounding boxes #
for (x, y, w, h) in rects:  
cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)
# apply non-maxima suppression to the bounding boxes #
rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])  
pick = non_max_suppression(rects, probs=None, overlapThresh=0.65) 
# draw the final bounding boxes #
for (xA, yA, xB, yB) in pick:   
cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)
# show some information on the number of bounding boxes #
Font = cv2.FONT_HERSHEY_SIMPLEX
Cv2.putText(frame, ‘Person’, (xA + 100, yA – 10), font, 0.5, (0, 0, 255), 2, cv2.LINE_AA   
# show live camera feed #
cV2.imshow(“Display_output”, frame)
k == cv2.waitkey(30) & 0XFF  
if k == 27:
break 
camera.release() 
cV2.destroyAllWindows()  
